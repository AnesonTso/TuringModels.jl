{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: [Turing] looking for good initial eps...\n",
      "└ @ Turing.Inference /Users/rob/.julia/packages/Turing/yF1Mq/src/inference/support/hmc_core.jl:245\n",
      "┌ Info: [Turing] found initial ϵ: 0.20036926269531252\n",
      "└ @ Turing.Inference /Users/rob/.julia/packages/Turing/yF1Mq/src/inference/support/hmc_core.jl:237\n",
      "\r[NUTS] Sampling... 16%  ETA: 0:00:05\u001b[K\n",
      "  ϵ:         0.13175888481991327\n",
      "  α:         0.9834303356686245\n",
      "  pre_cond:  [1.0, 1.0, 1.0, 1.0]\r\u001b[A\r\u001b[A\r\u001b[A┌ Info:  Adapted ϵ = 0.13069893710047473, std = [1.0, 1.0, 1.0, 1.0]; 1000 iterations is used for adaption.\n",
      "└ @ Turing.Inference /Users/rob/.julia/packages/Turing/yF1Mq/src/inference/adapt/adapt.jl:90\n",
      "\n",
      "\n",
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[K\u001b[A\r\u001b[K\u001b[A\r[NUTS] Sampling...100% Time: 0:00:02\u001b[K\n",
      "[NUTS] Finished with\n",
      "  Running time        = 1.7199732380000012;\n",
      "  #lf / sample        = 0.0;\n",
      "  #evals / sample     = 12.155;\n",
      "  pre-cond. metric    = [1.0, 1.0, 1.0, 1.0].\n",
      "Log evidence      = 0.0\n",
      "Iterations        = 1:2000\n",
      "Thinning interval = 1\n",
      "Chains            = 1\n",
      "Samples per chain = 2000\n",
      "parameters        = a, c\n",
      "\n",
      "Empirical Posterior Estimates\n",
      "───────────────────────────────────────────\n",
      "parameters\n",
      "    Mean     SD   Naive SE  MCSE     ESS  \n",
      "a -10.0258 0.6026   0.0135 0.0271 494.1250\n",
      "c  -6.0121 0.3459   0.0077 0.0153 511.6067\n",
      "\n",
      "Quantiles\n",
      "───────────────────────────────────────────\n",
      "parameters\n",
      "    2.5%     25.0%   50.0%   75.0%   97.5% \n",
      "a -22.4662 -10.0656 -9.9993 -9.9299 -6.0678\n",
      "c -12.9626  -6.0652 -5.9966 -5.9287 -3.8113\n",
      "\n",
      "Log evidence      = 0.0\n",
      "Iterations        = 1:2000\n",
      "Thinning interval = 1\n",
      "Chains            = 1\n",
      "Samples per chain = 2000\n",
      "pooled            = b, d\n",
      "\n",
      "Empirical Posterior Estimates\n",
      "──────────────────────────────────────────\n",
      "pooled\n",
      "    Mean    SD   Naive SE  MCSE     ESS  \n",
      "b -8.0187 0.4247   0.0095 0.0187 513.7126\n",
      "d -4.0143 0.3084   0.0069 0.0136 515.9884\n",
      "\n",
      "Quantiles\n",
      "──────────────────────────────────────────\n",
      "pooled\n",
      "    2.5%    25.0%   50.0%   75.0%   97.5% \n",
      "b -16.6249 -8.0628 -8.0002 -7.9379 -5.1982\n",
      "d -10.1611 -4.0715 -4.0031 -3.9347 -2.1303\n",
      "\n",
      "Log evidence      = 0.0\n",
      "Iterations        = 1:2000\n",
      "Thinning interval = 1\n",
      "Chains            = 1\n",
      "Samples per chain = 2000\n",
      "internals         = elapsed, epsilon, eval_num, lf_eps, lf_num, lp\n",
      "\n",
      "Empirical Posterior Estimates\n",
      "────────────────────────────────────────────────────────\n",
      "internals\n",
      "           Mean      SD    Naive SE   MCSE     ESS   \n",
      " elapsed   0.0009   0.0145   0.0003  0.0004 1291.7783\n",
      " epsilon   0.1173   0.0479   0.0011  0.0031  233.5272\n",
      "eval_num  12.1550   9.1564   0.2047  0.7445  151.2471\n",
      "  lf_eps   0.1173   0.0479   0.0011  0.0031  233.5272\n",
      "  lf_num   0.0000   0.0000   0.0000  0.0000       NaN\n",
      "      lp -32.4265 710.8707  15.8956 36.0876  388.0298\n",
      "\n",
      "Quantiles\n",
      "────────────────────────────────────────────────────────\n",
      "internals\n",
      "               2.5%       25.0%   50.0%   75.0%   97.5% \n",
      " elapsed  1.0000000×10⁻⁴  0.0003  0.0003  0.0004  0.6212\n",
      " epsilon  1.2300000×10⁻²  0.0971  0.1307  0.1307  0.9920\n",
      "eval_num   4.0000000×10⁰ 10.0000 10.0000 10.0000 94.0000\n",
      "  lf_eps  1.2300000×10⁻²  0.0971  0.1307  0.1307  0.9920\n",
      "  lf_num               0  0.0000  0.0000  0.0000  0.0000\n",
      "      lp -1.58060663×10⁴  3.0402  3.9352  4.5969  5.5272\n",
      "\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using TuringModels\n",
    "\n",
    "@model model() = begin\n",
    "    a ~ Normal(-10,.1)\n",
    "    b ~ Normal(-8,.1)\n",
    "    c ~ Normal(-6,.1)\n",
    "    d ~ Normal(-4,.1)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "Nsamples = 2000\n",
    "Nadapt = 1000\n",
    "draws = Nadapt+1 : Nsamples\n",
    "δ = .85\n",
    "sampler = NUTS(Nsamples, Nadapt, δ)\n",
    "\n",
    "sampler = Turing.NUTS(2000, 1000, 0.65)\n",
    "chn = sample(model(), sampler)\n",
    "\n",
    "chn1 = set_section(chn, Dict(\n",
    "  :parameters => [\"a\", \"c\"],\n",
    "  :pooled => [\"b\", \"d\"],\n",
    "  :internals => [\"elapsed\", \"epsilon\", \"eval_num\", \"lf_eps\", \"lf_num\", \"lp\"])\n",
    ")\n",
    "\n",
    "describe(chn1)\n",
    "describe(chn1, section=:pooled)\n",
    "describe(chn1, section=:internals)"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0-DEV.474"
  },
  "kernelspec": {
   "name": "julia-1.2",
   "display_name": "Julia 1.2.0-DEV.474",
   "language": "julia"
  }
 },
 "nbformat": 4
}
