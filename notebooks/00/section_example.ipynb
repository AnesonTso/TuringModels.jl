{
 "cells": [
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: [Turing] looking for good initial eps...\n",
      "└ @ Turing.Inference /Users/rob/.julia/packages/Turing/yF1Mq/src/inference/support/hmc_core.jl:245\n",
      "┌ Info: [Turing] found initial ϵ: 0.19892578125000002\n",
      "└ @ Turing.Inference /Users/rob/.julia/packages/Turing/yF1Mq/src/inference/support/hmc_core.jl:237\n",
      "┌ Info:  Adapted ϵ = 0.05089090174396743, std = [1.0, 1.0, 1.0, 1.0]; 1000 iterations is used for adaption.\n",
      "└ @ Turing.Inference /Users/rob/.julia/packages/Turing/yF1Mq/src/inference/adapt/adapt.jl:90\n",
      "[NUTS] Finished with\n",
      "  Running time        = 1.8534384040000016;\n",
      "  #lf / sample        = 0.0;\n",
      "  #evals / sample     = 16.0595;\n",
      "  pre-cond. metric    = [1.0, 1.0, 1.0, 1.0].\n",
      "Log evidence      = 0.0\n",
      "Iterations        = 1:2000\n",
      "Thinning interval = 1\n",
      "Chains            = 1\n",
      "Samples per chain = 2000\n",
      "parameters        = a, c\n",
      "\n",
      "Empirical Posterior Estimates\n",
      "──────────────────────────────────────────\n",
      "parameters\n",
      "    Mean    SD   Naive SE  MCSE   ESS\n",
      "a -9.9911 0.5240   0.0117 0.0094 2000\n",
      "c -5.9971 0.3241   0.0072 0.0062 2000\n",
      "\n",
      "Quantiles\n",
      "──────────────────────────────────────────\n",
      "parameters\n",
      "    2.5%     25.0%   50.0%   75.0%   97.5%\n",
      "a -21.4864 -10.0703 -9.9989 -9.9320 1.2062\n",
      "c -13.0472  -6.0762 -6.0032 -5.9337 0.6586\n",
      "\n",
      "Log evidence      = 0.0\n",
      "Iterations        = 1:2000\n",
      "Thinning interval = 1\n",
      "Chains            = 1\n",
      "Samples per chain = 2000\n",
      "pooled            = b, d\n",
      "\n",
      "Empirical Posterior Estimates\n",
      "─────────────────────────────────────────\n",
      "pooled\n",
      "    Mean    SD   Naive SE  MCSE   ESS\n",
      "b -7.9942 0.4074   0.0091 0.0072 2000\n",
      "d -3.9954 0.2774   0.0062 0.0051 2000\n",
      "\n",
      "Quantiles\n",
      "─────────────────────────────────────────\n",
      "pooled\n",
      "    2.5%    25.0%   50.0%   75.0%   97.5%\n",
      "b -16.8697 -8.0652 -8.0035 -7.9341 0.6081\n",
      "d  -9.6982 -4.0717 -4.0054 -3.9319 1.6854\n",
      "\n",
      "Log evidence      = 0.0\n",
      "Iterations        = 1:2000\n",
      "Thinning interval = 1\n",
      "Chains            = 1\n",
      "Samples per chain = 2000\n",
      "internals         = elapsed, epsilon, eval_num, lf_eps, lf_num, lp\n",
      "\n",
      "Empirical Posterior Estimates\n",
      "───────────────────────────────────────────────────────\n",
      "internals\n",
      "           Mean      SD    Naive SE   MCSE     ESS  \n",
      " elapsed   0.0009   0.0051   0.0001  0.0002 960.0899\n",
      " epsilon   0.0984   0.1306   0.0029  0.0111 139.0355\n",
      "eval_num  16.0595   8.4731   0.1895  1.0948  59.8933\n",
      "  lf_eps   0.0984   0.1306   0.0029  0.0111 139.0355\n",
      "  lf_num   0.0000   0.0000   0.0000  0.0000      NaN\n",
      "      lp -25.5845 627.3502  14.0280 29.0101 467.6493\n",
      "\n",
      "Quantiles\n",
      "───────────────────────────────────────────────────────\n",
      "internals\n",
      "              2.5%       25.0%   50.0%   75.0%   97.5% \n",
      " elapsed 1.0000000×10⁻⁴  0.0004  0.0009  0.0009  0.1628\n",
      " epsilon 2.0700000×10⁻²  0.0509  0.0509  0.1258  3.7589\n",
      "eval_num  4.0000000×10⁰ 10.0000 22.0000 22.0000 94.0000\n",
      "  lf_eps 2.0700000×10⁻²  0.0509  0.0509  0.1258  3.7589\n",
      "  lf_num              0  0.0000  0.0000  0.0000  0.0000\n",
      "      lp -1.4631501×10⁴  2.6440  3.7397  4.5077  5.4948\n",
      "\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using TuringModels\n",
    "\n",
    "@model model() = begin\n",
    "    a ~ Normal(-10,.1)\n",
    "    b ~ Normal(-8,.1)\n",
    "    c ~ Normal(-6,.1)\n",
    "    d ~ Normal(-4,.1)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "Nsamples = 2000\n",
    "Nadapt = 1000\n",
    "draws = Nadapt+1 : Nsamples\n",
    "δ = .85\n",
    "sampler = NUTS(Nsamples, Nadapt, δ)\n",
    "\n",
    "sampler = Turing.NUTS(2000, 1000, 0.65)\n",
    "chn = sample(model(), sampler)\n",
    "\n",
    "chn1 = set_section(chn, Dict(\n",
    "  :parameters => [\"a\", \"c\"],\n",
    "  :pooled => [\"b\", \"d\"],\n",
    "  :internals => [\"elapsed\", \"epsilon\", \"eval_num\", \"lf_eps\", \"lf_num\", \"lp\"])\n",
    ")\n",
    "\n",
    "describe(chn1)\n",
    "describe(chn1, section=:pooled)\n",
    "describe(chn1, section=:internals)"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0-DEV.483"
  },
  "kernelspec": {
   "name": "julia-1.2",
   "display_name": "Julia 1.2.0-DEV.483",
   "language": "julia"
  }
 },
 "nbformat": 4
}
